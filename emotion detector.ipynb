{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Emotion detector using Keras"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importing Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dense,Dropout,Activation,Conv2D,MaxPooling2D,BatchNormalization,Flatten\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import rmsprop_v2\n",
    "from keras.callbacks import EarlyStopping,ReduceLROnPlateau,ModelCheckpoint\n",
    "from keras.models import load_model\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import seaborn as sns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reading all images & storing them to a dataframe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int2emotions = {0:'Angry',1:'Fear',2:'Happy',3:'Neutral',4:'Sad',5:'Surprise'}\n",
    "emotions2int = {'Angry':0,'Fear':1,'Happy':2,'Neutral':3,'Sad':4,'Surprise':5}\n",
    "dic = {'images':[], 'labels':[], 'purpose':[]}\n",
    "    \n",
    "for d in os.listdir('fer2013/'):\n",
    "    print(d)\n",
    "    for emotion in os.listdir(f'fer2013/{d}'):\n",
    "        print(emotion)\n",
    "        for i in os.listdir(f'fer2013/{d}/{emotion}'):\n",
    "            img = cv2.imread(f'fer2013/{d}/{emotion}/{i}',0)\n",
    "            img = img.reshape(48,48,1)\n",
    "            \n",
    "            dic['images'].append(img)\n",
    "            dic['labels'].append(emotion)\n",
    "            \n",
    "            if d=='train':\n",
    "                dic['purpose'].append('T')\n",
    "            else:\n",
    "                dic['purpose'].append('V')\n",
    "df = pd.DataFrame(dic)\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Extracting Training data & Validation data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = df[df['purpose']=='T']\n",
    "val_data = df[df['purpose']=='V']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['labels'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Taking equal instances of all classes \n",
    "\n",
    "happy_df = train_data[train_data['labels']=='Happy'].sample(n=3171)\n",
    "neutral_df = train_data[train_data['labels']=='Neutral'].sample(n=3171)\n",
    "sad_df = train_data[train_data['labels']=='Sad'].sample(n=3171)\n",
    "fear_df = train_data[train_data['labels']=='Fear'].sample(n=3171)\n",
    "angry_df = train_data[train_data['labels']=='Angry'].sample(n=3171)\n",
    "surprise_df = train_data[train_data['labels']=='Surprise'].sample(n=3171)\n",
    "train_data = pd.concat([happy_df,neutral_df,sad_df,fear_df,angry_df,surprise_df])\n",
    "train_data = train_data.sample(frac=1)\n",
    "train_data.reset_index(inplace=True)\n",
    "train_data.drop('index',inplace=True,axis=1)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['labels'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(train_data['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size= 32\n",
    "classes = 6\n",
    "rows,columns=48,48\n",
    "\n",
    "train_labels = list(train_data['labels'].replace(emotions2int))\n",
    "train_labels = to_categorical(train_labels)\n",
    "val_labels = list(val_data['labels'].replace(emotions2int))\n",
    "val_labels = to_categorical(val_labels)\n",
    "train_data = list(train_data['images'])\n",
    "train_data = np.array(train_data)\n",
    "val_data = list(val_data['images'])\n",
    "val_data = np.array(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Creating the Emotion Detector model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# First Block\n",
    "model.add(Conv2D(64,(3,3),activation='elu',input_shape=(rows,columns,1),kernel_initializer='he_normal',padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(64,(3,3),activation='elu',input_shape=(rows,columns,1),kernel_initializer='he_normal',padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Second Block\n",
    "model.add(Conv2D(128,(3,3),activation='elu',kernel_initializer='he_normal',padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(128,(3,3),activation='elu',kernel_initializer='he_normal',padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Third Block\n",
    "model.add(Conv2D(256,(3,3),activation='elu',kernel_initializer='he_normal',padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(256,(3,3),activation='elu',kernel_initializer='he_normal',padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Fourth Block\n",
    "model.add(Conv2D(512,(3,3),activation='elu',kernel_initializer='he_normal',padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(512,(3,3),activation='elu',kernel_initializer='he_normal',padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Fifth Block\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256,activation='elu',kernel_initializer='he_normal'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# Sixth Block\n",
    "model.add(Dense(128,activation='elu',kernel_initializer='he_normal'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# Seventh Block\n",
    "model.add(Dense(64,activation='elu',kernel_initializer='he_normal'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# Eighth Block\n",
    "model.add(Dense(classes,activation='softmax',kernel_initializer='he_normal'))\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Declaring Earlystopping & Checkpoint callbacks\n",
    "\n",
    "checkpoint = ModelCheckpoint('model\\\\6_class_emotion_detector_V2.h5', save_best_only=True, mode='min', monitor='val_loss', verbose=1)\n",
    "earlystopping = EarlyStopping(patience=10, verbose=1, min_delta=0, monitor='val_loss', restore_best_weights=True)\n",
    "callbacks = [checkpoint, earlystopping]\n",
    "model.compile(metrics=['accuracy'], optimizer='rmsprop', loss='categorical_crossentropy')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samples = 28273\n",
    "validation_samples = 3534\n",
    "batch_size = 64\n",
    "epochs=30\n",
    "history = model.fit(train_data, train_labels, epochs=epochs, steps_per_epoch=train_samples//batch_size, validation_data=(val_data,val_labels), validation_steps=validation_samples//batch_size, callbacks=callbacks)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Live Prediction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "\n",
    "int2emotions = {0:'Angry',1:'Fear',2:'Happy',3:'Neutral',4:'Sad',5:'Surprise'}\n",
    "model = load_model('model\\\\6_class_emotion_detector_V2.h5')\n",
    "cap = cv2.VideoCapture(0)\n",
    "classifier = cv2.CascadeClassifier('Haarcascades\\\\haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_face(frame):\n",
    "    faces=classifier.detectMultiScale(frame,1.3,4)\n",
    "    if faces==():\n",
    "        return frame\n",
    "    for x,y,w,h in faces:\n",
    "        cv2.rectangle(frame,(x,y),(x+w,y+h),(172,42,251),2)\n",
    "        face = frame[y:y+h,x:x+w]\n",
    "        face = cv2.cvtColor(face,cv2.COLOR_BGR2GRAY)\n",
    "        face = cv2.resize(face,(48,48))\n",
    "        face = face.reshape(1,48,48,1)\n",
    "        cv2.putText(frame,text=int2emotions[np.argmax(model.predict(face))],\n",
    "                    org=(x,y-15),fontFace=cv2.FONT_HERSHEY_SIMPLEX,fontScale=1,color=(106,40,243),thickness=2)\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while 1:\n",
    "    ret,frame= cap.read()\n",
    "    if ret==True:\n",
    "        cv2.imshow('emotion_detector',detect_face(frame))\n",
    "        if cv2.waitKey(1)==27:\n",
    "            break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5 (tags/v3.10.5:f377153, Jun  6 2022, 16:14:13) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "52634da84371cba311ea128a5ea7cdc41ff074b781779e754b270ff9f8153cee"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
